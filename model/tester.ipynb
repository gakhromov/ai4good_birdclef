{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from config import config\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import random\n",
    "from scipy import fft\n",
    "import noisereduce as nr\n",
    "import soundfile\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import lzma\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import seaborn as sb\n",
    "import pathlib\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate augmented df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.relpath('../datasets/numpy_mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/numpy_mel/train_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new augmented df\n",
    "cols = ['primary_label', 'secondary_labels', 'path']\n",
    "df_augmented = pd.DataFrame(columns=cols)\n",
    "\n",
    "for idx, item in df.iterrows():\n",
    "    path_bird = item['filename'].split('.')[0]\n",
    "    path = os.path.join(root, 'data', path_bird)\n",
    "    augmented_files = glob.glob(f'{path}*')\n",
    "    \n",
    "    # add new row to the augmented for each additional file\n",
    "    for f in augmented_files:\n",
    "        data = {\n",
    "            'path': [f.replace('\\\\', '/')],\n",
    "            'file': path_bird,\n",
    "            'primary_label': [item.primary_label],\n",
    "            'secondary_labels': [item.secondary_labels]\n",
    "        }\n",
    "        new = pd.DataFrame(data=data)\n",
    "        df_augmented = pd.concat((df_augmented, new), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import combine_labels\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = df['primary_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_augmented.copy()\n",
    "classes = mapping\n",
    "df['label'] = [combine_labels(df['primary_label'][idx], df['secondary_labels'][idx]) for idx in range(len(df))]\n",
    "secondary = [np.sum([np.where(item == classes, 1, 0) for item in row], axis=0) for row in df['label']]\n",
    "df['sec_enc'] = secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "primary = encoder.fit_transform(df['primary_label'])\n",
    "df['pri_enc'] = primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{root}/augmented', df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'{root}/augmented.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Augmentations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class GaussianNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y ** 2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        white_noise = np.random.randn(len(y))\n",
    "        a_white = np.sqrt(white_noise ** 2).max()\n",
    "        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class PinkNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y ** 2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n",
    "        a_pink = np.sqrt(pink_noise ** 2).max()\n",
    "        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.noise_level = (0.0, max_noise_level)\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        noise_level = np.random.uniform(*self.noise_level)\n",
    "        noise = np.random.randn(len(y))\n",
    "        augmented = (y + noise * noise_level).astype(y.dtype)\n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorednoise as cn\n",
    "\n",
    "def add_white_noise(y, min_snr=5, max_snr=20):\n",
    "    snr = np.random.uniform(min_snr, max_snr)\n",
    "    a_noise = 1 / (10 ** (snr / 20))\n",
    "\n",
    "    white_noise = np.random.randn(len(y))\n",
    "    a_white = np.sqrt(white_noise ** 2).max()\n",
    "    augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n",
    "    return augmented\n",
    "\n",
    "\n",
    "def add_pink_noise(y, min_snr=5, max_snr=20):\n",
    "    snr = np.random.uniform(min_snr, max_snr)\n",
    "    a_noise = 1 / (10 ** (snr / 20))\n",
    "\n",
    "    pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n",
    "    a_pink = np.sqrt(pink_noise ** 2).max()\n",
    "    augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n",
    "    return augmented  \n",
    "\n",
    "\n",
    "def add_random_noise(y, max_noise_level=0.5):\n",
    "    noise_level = np.random.uniform(0, max_noise_level)\n",
    "    noise = np.random.randn(len(y))\n",
    "    augmented = (y + noise * noise_level).astype(y.dtype)\n",
    "    return augmented\n",
    "\n",
    "\n",
    "def add_noise(y, noise_scale=0.5):\n",
    "    noise_fn = [add_white_noise, add_pink_noise, add_random_noise]\n",
    "    return random.choice(noise_fn)(y) * noise_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(22_050*30)\n",
    "y_noisy = add_noise(y, noise_scale=0.2)\n",
    "plt.plot(y, color='r')\n",
    "plt.plot(y_noisy, alpha=0.2, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel(y, reduce_noise=True):\n",
    "\n",
    "    # extract features\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=22050, fmin=200, fmax=10000, n_mels=64, n_fft=1024)\n",
    "    # convert to db and normalize to max=0dB\n",
    "    mel_spec = librosa.power_to_db(mel_spec, ref=np.max, top_db=80)\n",
    "\n",
    "    return mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(get_mel(y_noisy))\n",
    "print(y_noisy.max(), y_noisy.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_noisy = torch.FloatTensor(y_noisy)\n",
    "spec = torchaudio.transforms.MelSpectrogram(sample_rate=22_050, n_fft=1024, f_min=200, f_max=10_000, hop_length=512, n_mels=64, normalized=True)(y_noisy)\n",
    "spec = torchaudio.transforms.AmplitudeToDB(top_db=80)(spec)\n",
    "print(spec.max(), spec.min(), spec.shape)\n",
    "librosa.display.specshow(spec.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataset\n",
    "from helpers import dotdict\n",
    "args = dotdict({'data_path': '../datasets/numpy_mel/', 'use_secondary': False})\n",
    "datasets = get_dataset(args)\n",
    "import colorednoise as cn\n",
    "from models import MelDB\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, test_gen = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(train_gen):\n",
    "    img, label = item\n",
    "    img, label = img[0], label[0]\n",
    "    img = img.squeeze().cpu().numpy()\n",
    "    label = label.squeeze().cpu().numpy()\n",
    "    print(img.shape)\n",
    "    plt.title(label)\n",
    "    print(img.min(), img.max())\n",
    "    librosa.display.specshow(img)\n",
    "    plt.show()\n",
    "    if idx > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.DataFrame()\n",
    "df_orig['class'] = os.listdir('../datasets/birdclef22/train_audio/')\n",
    "l = []\n",
    "for folder in df_orig['class']:\n",
    "    l.append(len(os.listdir(f'../datasets/birdclef22/train_audio/{folder}')))\n",
    "\n",
    "df_orig['num'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['class'] = os.listdir('../datasets/numpy_mel/data/')\n",
    "l = []\n",
    "for folder in df['class']:\n",
    "    l.append(len(os.listdir(f'../datasets/numpy_mel/data/{folder}')))\n",
    "\n",
    "df['num'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame()\n",
    "df_diff['class'] = df_orig['class']\n",
    "df_diff['diff'] = df['num'] - df_orig['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set_style('white')\n",
    "sb.set_theme(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,9))\n",
    "plt.title(\"Original Class Distribution\")\n",
    "ax = sb.barplot(data=df_orig.sort_values('num', ascending=False), x='class', y='num')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('original_dist', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,9))\n",
    "plt.title(\"Augmented DS Class Distribution\")\n",
    "ax = sb.barplot(data=df.sort_values('num', ascending=False), x='class', y='num')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('augmented_dist', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,9))\n",
    "plt.title(\"Augmentation per Class\")\n",
    "ax = sb.barplot(data=df_orig, x='class', y='num', color='k')\n",
    "ax = sb.barplot(data=df_diff, x='class', y='diff', color='r')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('augemnted_detail', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.choice(os.listdir('../datasets/numpy_mel/data/afrsil1/'))\n",
    "mel = np.load(f'../datasets/numpy_mel/data/afrsil1/{test}')\n",
    "mel = mel['mel']\n",
    "\n",
    "# show the spec\n",
    "plt.figure(figsize=(16,4))\n",
    "librosa.display.specshow(mel, sr=1024)\n",
    "plt.title(f'{test}--{mel.shape}')\n",
    "plt.show()\n",
    "Audio(filename=f\"../datasets/birdclef22/train_audio/afrsil1/{test.split('_')[0]}.ogg\", rate=22_050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BirdClefMelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/numpy_mel/augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict({'data_path': '../datasets/numpy_mel/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BirdClefMelDataset(df=df, args=args, use_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.relpath('..\\datasets\\\\numpy_mel\\data\\\\afrsil1\\XC177993_s0_ps_-1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.load(p, allow_pickle=True)\n",
    "img = img.f.mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.min(), img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1,1,1,1], [1,2,3,4]]).reshape((-1,1,1)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_normal = img\n",
    "mel_normal = mel_normal - np.min(mel_normal)\n",
    "if np.max(mel_normal) != 0:\n",
    "    mel_normal /= np.max(mel_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mel_normal.min(), mel_normal.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(mel_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = ds.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(img.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import loss_bcefocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([0,0,0,0,1])\n",
    "pred =   torch.tensor([0,0.99,0,0,0.78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bcefocal(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 20_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa vs npy loading\n",
    "test_samples = df.sample(100)['filename']\n",
    "total_samples = 0\n",
    "start = time.time()\n",
    "for t in tqdm(test_samples):\n",
    "    file = os.path.join('../datasets/birdclef22/train_audio/', t)\n",
    "    #y = torchaudio.load(file)[0].numpy()\n",
    "    #shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=2, res_type='kaiser_fast')\n",
    "    y, sr = librosa.load(file, sr=None, res_type='kaiser_fast', duration=None)\n",
    "    samps = len(y)\n",
    "    total_samples += samps\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(df)\n",
    "total = stop-start\n",
    "avg = total / 100\n",
    "avg_per_time = total_samples / 100\n",
    "print(\"total time\", total)\n",
    "print(\"average time\", avg)\n",
    "print(\"samples total\", avg_per_time)\n",
    "print(\"time to load ds\", dataset_length*avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiser fast\n",
    "-----------------\n",
    "    total time 35.63866972923279\n",
    "    average time 0.35638669729232786\n",
    "    samples total 912355.55\n",
    "    time to load ds 5293.0552281856535\n",
    "\n",
    "Kaiser best\n",
    "-----------------\n",
    "    total time 80.84255528450012\n",
    "    average time 0.8084255528450012\n",
    "    samples total 943532.88\n",
    "    time to load ds 12006.736310853958\n",
    "\n",
    "Kaiser fast 30s\n",
    "-----------------\n",
    "    total time 16.148550510406494\n",
    "    average time 0.16148550510406495\n",
    "    samples total 413094.96\n",
    "    time to load ds 2398.3827218055726"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading times:\n",
    "kaiser_best : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(samples)\n",
    "sample_reduced = nr.reduce_noise(sample, sr=sr)\n",
    "shift = librosa.effects.pitch_shift(sample, sr=sr, n_steps=1, res_type='kaiser_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(shift, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sample, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sample_reduced, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('test.npy')\n",
    "os.remove('test.ogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('test.npz', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfile.write('test.ogg', sample, sr, format='ogg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44ff33fa2e24d961b937d20c36da57d187e4b8904719489e912c1e1d5e357bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
